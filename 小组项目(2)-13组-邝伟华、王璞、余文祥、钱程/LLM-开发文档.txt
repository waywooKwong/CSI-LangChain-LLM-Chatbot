LLM-小组项目(2)-13组-邝伟华、王璞、余文祥、钱程-20240724

步骤一：项目规划与需求分析
	1. 项目目标：软件工程开发的客服助手
	2. 核心功能：客服对话
	3. 确定技术架构和工具：
		1. 框架：LangChain
		2. Embedding模型：m3e-base
		3. 数据库：Qdrant
		4. 大模型：智谱清言GLM
		5. 前后端：前后端分离FaskAPI + Vue3
步骤二：数据准备与向量知识库构建
	1. 收集和整理用户提供的文档
		LangChain AgentTool 网页搜索工具（Exa、Serpapi）
		根据指定关键词获取网页URL
		再利用 Python 工具爬取网页内容，收集整理成文本
	2. 文档词向量化
		使用文本嵌入模型 m3e-base（Embedding）对分割后文档向量化
	3. 向量化后的文档导入Qdrant知识库，建立知识库索引
		文本向量化存储进 Qdrant 库，metadata 标签特征
		后续使用 LangSmith 进行链构造等的管理
步骤三：大模型集成与 API 连接
	LangChain 集成配置 API 连接，主要使用 GLM智谱清言
步骤四：核心功能实现
	1. Prompt Engineering 实现LLM回答
	2. 用户上传文件读取
	2. 流式回复，允许多轮对话
步骤五：核心功能迭代优化
	1. 验证评估，收集 BadCase
	2. 根据 Bad Case 迭代优化核心功能实现
	3. LangSmith 后台管理链调用信息
步骤六：前端与用户交互界面开发
	1. Vue架构前端界面
	2. 用户上传文档、创建知识库的功能
	3. 设计用户界面，问题输入、知识库选择、历史记录展示
步骤七：部署测试与上线
	1. 部署项目到服务器或云平台，确保可在互联网上访问
	2. 进行生产环境测试，确保系统稳定
	3. 上线并向用户发布
步骤八：维护与持续改进
	1. 监测系统性能和用户反馈，及时处理问题
	2. 定期更新知识库，添加新的文档和信息处理
	3. 收集用户需求，进行系统改进和功能扩展